Deep learning has shown great potential in improving the efficiency of airfoil flow field prediction by reducing the computational cost compared to traditional numerical methods. However, the large number of parameters in deep learning models can lead to excessive resource consumption, hurting their performance in real-time applications. To address these challenges, we propose a novel compression mechanism called Physics-Informed Neural Network Compression Mechanism (PINNCoM) to reduce model size and improve efficiency. PINNCoM consists of two stages: knowledge distillation and self-adaptive pruning. The knowledge distillation extracts key parameters from a given teacher model, i.e., a neural network model for airfoil flow field prediction, to construct a student model. By designing a physical information loss term based on the Navier-Stokes equations during the knowledge distillation, the student model can maintain fewer parameters and accurately predict the flow field in the meantime. The second stage is self-adaptive pruning, which further compresses the student model by removing redundant channels in the network while preserving its accuracy. Specifically, a reward function is designed to incorporate both physical and channel information to ensure the prediction results align with physical laws while prioritizing critical channels for retention, enabling a flexible and efficient pruning mechanism. Experimental results on airfoil flow field prediction datasets demonstrate that PINNCoM effectively reduces computational complexity with minimal accuracy loss, offering a promising solution for reducing computational complexity in fluid dynamics applications.


![image](https://github.com/user-attachments/assets/4609f324-21f2-441b-bc89-b601199dae94)
